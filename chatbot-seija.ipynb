{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2870315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalação das dependências\n",
    "!pip install -U langgraph requests langchain-openai openai python-dotenv langchain langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a90b39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "from typing import Annotated, List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import Tool, initialize_agent, AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_base=\"http://plataforma.sobdemanda.mandu.piaui.pro\",\n",
    "    openai_api_key=\"sk-60gBh1n5AVAsgJ2HZKq4HA\",\n",
    "    model=\"Qwen3-30B-A3B\",\n",
    "    temperature=0.8\n",
    ")\n",
    "\n",
    "# --- Estrutura do estado ---\n",
    "class IntencaoUsuario(TypedDict):\n",
    "    intencao: str\n",
    "    cod_processo: str\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[List, add_messages]\n",
    "    intencao_usuario: IntencaoUsuario\n",
    "    is_valid: bool\n",
    "\n",
    "# --- Nós do LangGraph ---\n",
    "def qwen_chat_intencao(state: ChatState) -> ChatState:\n",
    "    try:\n",
    "        user_input = state[\"messages\"][-1]\n",
    "\n",
    "        assistent_prompt = (\n",
    "            'Você é um assistente jurídico. Analise a mensagem abaixo e retorne apenas um JSON no formato: '\n",
    "            '{\"intencao\": str, \"cod_processo\": str}. '\n",
    "            'Valores válidos para \"intencao\": \"resumo\" ou \"andamento\". '\n",
    "            '\"cod_processo\" deve seguir o formato 99999.999999/9999-99.'\n",
    "        )\n",
    "\n",
    "        response = llm.invoke([\n",
    "            {\"role\": \"system\", \"content\": assistent_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_input.content}\n",
    "        ])\n",
    "\n",
    "        print(\"Conteúdo recebido do modelo:\\n\", response.content)\n",
    "\n",
    "        try:\n",
    "            resposta_json = json.loads(response.content.strip(\"```json\").strip(\"```\").strip())\n",
    "        except json.JSONDecodeError:\n",
    "            erro_msg = (\n",
    "                \"O modelo não retornou JSON válido.\\n\"\n",
    "                f\"Conteúdo recebido:\\n{response.content}\"\n",
    "            )\n",
    "            state[\"messages\"].append(AIMessage(content=erro_msg))\n",
    "            state[\"intencao_usuario\"] = {\"intencao\": \"\", \"cod_processo\": \"\"}\n",
    "            return state\n",
    "\n",
    "        state[\"intencao_usuario\"] = resposta_json\n",
    "        intencao = resposta_json.get(\"intencao\", \"\")\n",
    "        state[\"messages\"].append(AIMessage(content=f\"Intenção detectada: '{intencao}'\"))\n",
    "\n",
    "        return state\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"messages\": [AIMessage(content=f\"Erro inesperado: {str(e)}\")]}\n",
    "\n",
    "def verificar_numero_processo(state: ChatState) -> ChatState:\n",
    "    processo = state[\"intencao_usuario\"].get(\"cod_processo\", \"\")\n",
    "    padrao = r\"([0-9]{5,})\\.?([0-9]{6,})\\/?([0-9]{4,})-?([0-9]{2,})\"\n",
    "    state[\"is_valid\"] = bool(re.match(padrao, processo))\n",
    "    return state\n",
    "\n",
    "def executar_intencao_processo(state: ChatState) -> ChatState:\n",
    "    intencao = state[\"intencao_usuario\"].get(\"intencao\", \"\")\n",
    "    processo = state[\"intencao_usuario\"].get(\"cod_processo\", \"\")\n",
    "    valido = state.get(\"is_valid\", False)\n",
    "\n",
    "    if not valido:\n",
    "        resposta = f\"Número de processo inválido: {processo}.\"\n",
    "        state[\"messages\"].append(AIMessage(content=resposta))\n",
    "        return state\n",
    "\n",
    "    try:\n",
    "        processo_formatado = processo.replace(\".\", \"\").replace(\"/\", \"\").replace(\"-\", \"\")\n",
    "\n",
    "        if intencao == \"resumo\":\n",
    "            response_resumo = requests.get(f\"http://127.0.0.1:8000/resumo/{processo_formatado}\")\n",
    "            response_resumo.raise_for_status()\n",
    "            dados_processo = response_resumo.json()\n",
    "            resposta = f\"Resumo do processo {processo}:\\n\\n{dados_processo.get('resumo', 'Resumo não encontrado.')}\"\n",
    "        elif intencao == \"andamento\":\n",
    "            response_andamento = requests.get(f\"http://127.0.0.1:8000/andamento/{processo_formatado}\")\n",
    "            response_andamento.raise_for_status()\n",
    "            dados_processo = response_andamento.json()\n",
    "            resposta = f\"Andamento do processo {processo}:\\n\\n{dados_processo.get('andamento', 'Andamento não encontrado.')}\"\n",
    "        else:\n",
    "            resposta = f\"Intenção '{intencao}' não reconhecida ou não suportada.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        resposta = f\"Erro ao consultar API local: {str(e)}\"\n",
    "\n",
    "    state[\"messages\"].append(AIMessage(content=resposta))\n",
    "    return state\n",
    "\n",
    "\n",
    "\n",
    "workflow = StateGraph(ChatState)\n",
    "workflow.add_node(\"qwen_chat_intencao\", qwen_chat_intencao)\n",
    "workflow.add_node(\"verificar_numero_processo\", verificar_numero_processo)\n",
    "workflow.add_node(\"executar_intencao_processo\", executar_intencao_processo)\n",
    "workflow.add_edge(START, \"qwen_chat_intencao\")\n",
    "workflow.add_edge(\"qwen_chat_intencao\", \"verificar_numero_processo\")\n",
    "workflow.add_edge(\"verificar_numero_processo\", \"executar_intencao_processo\")\n",
    "workflow.add_edge(\"executar_intencao_processo\", END)\n",
    "\n",
    "chatbot = workflow.compile()\n",
    "\n",
    "entrada_usuario = \"me fale sobre o resumo do processo 00002.003059/2024-15\"\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=entrada_usuario)],\n",
    "    \"intencao_usuario\": {\"intencao\": \"\", \"cod_processo\": \"\"},\n",
    "    \"is_valid\": False\n",
    "}\n",
    "\n",
    "resultado = chatbot.invoke(initial_state)\n",
    "\n",
    "for m in resultado[\"messages\"]:\n",
    "    print(f\"{m.type.upper()}: {m.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907047fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteúdo recebido do modelo:\n",
      " \n",
      "\n",
      "{\"intencao\": \"resumo\", \"cod_processo\": \"00002.003059/2024-15\"}\n",
      "HUMAN: me fale sobre o resumo do processo 00002.003059/2024-15\n",
      "AI: Intenção detectada: 'resumo'\n",
      "AI: \n",
      "\n",
      "O processo **00002.003059/2024-15** refere-se a um **memorando oficial** emitido pelo **Núcleo Estratégico de Tecnologia e Governo Digital (NTGD)** da **Secretaria de Administração do Estado do Piauí (SEAD-PI)**. Abaixo estão os principais detalhes:\n",
      "\n",
      "### **Informações Principais**:\n",
      "- **Tipo de Documento**: Memorando (SEAD_MEMORANDO).  \n",
      "- **Número do Processo**: 00002.003059/2024-15.  \n",
      "- **Data de Elaboração**: 09 de abril de 2024.  \n",
      "- **Unidade Solicitante**: Núcleo Estratégico de Tecnologia e Governo Digital (NTGD) – SEAD-PI.  \n",
      "- **Assunto**: Solicitação de autorização para contratação de **estagiário do curso de Engenharia de Software**.  \n",
      "- **Destinatário**: Superintendência de Gestão de Pessoas (SGP) – SEAD-PI.  \n",
      "\n",
      "### **Detalhes da Solicitação**:\n",
      "- **Objetivo**: Inclusão de um estagiário no quadro de pessoal do NTGD.  \n",
      "- **Fundamento Legal**: Decreto Estadual nº 18.142/2019.  \n",
      "- **Assinatura**: Eletrônica de **Ubaldo de Sá Neves Júnior**, diretor da unidade.  \n",
      "- **Autenticidade**: O documento inclui um código verificador e um link para conferência no sistema SEI (Sistema Eletrônico de Informações).  \n",
      "\n",
      "### **Acesso ao Documento**:\n",
      "- **Link**: [https://sei.pi.gov.br/sei/controlador.php?acao=procedimento_trabalhar&id_procedimento=13378595&id_documento=13378662](https://sei.pi.gov.br/sei/controlador.php?acao=procedimento_trabalhar&id_procedimento=13378595&id_documento=13378662)  \n",
      "- **Código SEI**: 011947061.  \n",
      "\n",
      "### **Resumo**:\n",
      "O documento é um **pedido formal de contratação de estagiário**, com estrutura e formalidades típicas de comunicação interna governamental. A solicitação inclui todos os requisitos legais e administrativos necessários para validação, além de referências ao processo específico e à autenticidade do documento.  \n",
      "\n",
      "Se houver necessidade de mais detalhes, o acesso ao link fornecido permite visualizar o documento completo.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import requests\n",
    "from typing import Annotated, List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_base=\"http://plataforma.sobdemanda.mandu.piaui.pro\",\n",
    "    openai_api_key=\"sk-60gBh1n5AVAsgJ2HZKq4HA\",\n",
    "    model=\"Qwen3-30B-A3B\",\n",
    "    temperature=0.8\n",
    ")\n",
    "\n",
    "class IntencaoUsuario(TypedDict):\n",
    "    intencao: str\n",
    "    cod_processo: str\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[List, add_messages]\n",
    "    intencao_usuario: IntencaoUsuario\n",
    "    is_valid: bool\n",
    "\n",
    "def responder_com_ia(texto_api: str, processo: str, intencao: str) -> str:\n",
    "    prompt = (\n",
    "        f\"Com base nas informações abaixo, responda ao usuário sobre o processo {processo}.\\n\\n\"\n",
    "        f\"{texto_api}\"\n",
    "    )\n",
    "\n",
    "    resposta = llm.invoke([\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ])\n",
    "\n",
    "    return resposta.content\n",
    "\n",
    "def qwen_chat_intencao(state: ChatState) -> ChatState:\n",
    "    try:\n",
    "        user_input = state[\"messages\"][-1]\n",
    "\n",
    "        assistent_prompt = (\n",
    "            'Analise a mensagem abaixo e retorne apenas um JSON no formato: '\n",
    "            '{\"intencao\": str, \"cod_processo\": str}. '\n",
    "            'Valores válidos para \"intencao\": \"resumo\" ou \"andamento\". '\n",
    "            '\"cod_processo\" deve seguir o formato 99999.999999/9999-99.'\n",
    "        )\n",
    "\n",
    "        response = llm.invoke([\n",
    "            {\"role\": \"system\", \"content\": assistent_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_input.content}\n",
    "        ])\n",
    "\n",
    "        print(\"Conteúdo recebido do modelo:\\n\", response.content)\n",
    "\n",
    "        try:\n",
    "            resposta_json = json.loads(response.content.strip(\"```json\").strip(\"```\").strip())\n",
    "        except json.JSONDecodeError:\n",
    "            erro_msg = (\n",
    "                \"O modelo não retornou JSON válido.\\n\"\n",
    "                f\"Conteúdo recebido:\\n{response.content}\"\n",
    "            )\n",
    "            state[\"messages\"].append(AIMessage(content=erro_msg))\n",
    "            state[\"intencao_usuario\"] = {\"intencao\": \"\", \"cod_processo\": \"\"}\n",
    "            return state\n",
    "\n",
    "        state[\"intencao_usuario\"] = resposta_json\n",
    "        intencao = resposta_json.get(\"intencao\", \"\")\n",
    "        state[\"messages\"].append(AIMessage(content=f\"Intenção detectada: '{intencao}'\"))\n",
    "\n",
    "        return state\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"messages\": [AIMessage(content=f\"Erro inesperado: {str(e)}\")]}\n",
    "\n",
    "def verificar_numero_processo(state: ChatState) -> ChatState:\n",
    "    processo = state[\"intencao_usuario\"].get(\"cod_processo\", \"\")\n",
    "    padrao = r\"([0-9]{5})\\.([0-9]{6})\\/([0-9]{4})-([0-9]{2})\"\n",
    "    state[\"is_valid\"] = bool(re.match(padrao, processo))\n",
    "    return state\n",
    "\n",
    "def executar_intencao_processo(state: ChatState) -> ChatState:\n",
    "    intencao = state[\"intencao_usuario\"].get(\"intencao\", \"\")\n",
    "    processo = state[\"intencao_usuario\"].get(\"cod_processo\", \"\")\n",
    "    valido = state.get(\"is_valid\", False)\n",
    "\n",
    "    if not valido:\n",
    "        resposta = f\"Número de processo inválido: {processo}.\"\n",
    "        state[\"messages\"].append(AIMessage(content=resposta))\n",
    "        return state\n",
    "\n",
    "    try:\n",
    "        processo_formatado = processo.replace(\".\", \"\").replace(\"/\", \"\").replace(\"-\", \"\")\n",
    "\n",
    "        if intencao == \"resumo\":\n",
    "            response = requests.get(f\"http://127.0.0.1:8000/resumo/{processo_formatado}\")\n",
    "        elif intencao == \"andamento\":\n",
    "            response = requests.get(f\"http://127.0.0.1:8000/andamento/{processo_formatado}\")\n",
    "        else:\n",
    "            resposta = f\"Intenção '{intencao}' não reconhecida ou não suportada.\"\n",
    "            state[\"messages\"].append(AIMessage(content=resposta))\n",
    "            return state\n",
    "\n",
    "        response.raise_for_status()\n",
    "        texto_api = response.text.strip()\n",
    "\n",
    "        resposta_texto = responder_com_ia(texto_api, processo, intencao)\n",
    "        state[\"messages\"].append(AIMessage(content=resposta_texto))\n",
    "\n",
    "    except Exception as e:\n",
    "        resposta = f\"Erro ao consultar API local: {str(e)}\"\n",
    "        state[\"messages\"].append(AIMessage(content=resposta))\n",
    "\n",
    "    return state\n",
    "\n",
    "workflow = StateGraph(ChatState)\n",
    "workflow.add_node(\"qwen_chat_intencao\", qwen_chat_intencao)\n",
    "workflow.add_node(\"verificar_numero_processo\", verificar_numero_processo)\n",
    "workflow.add_node(\"executar_intencao_processo\", executar_intencao_processo)\n",
    "\n",
    "workflow.add_edge(START, \"qwen_chat_intencao\")\n",
    "workflow.add_edge(\"qwen_chat_intencao\", \"verificar_numero_processo\")\n",
    "workflow.add_edge(\"verificar_numero_processo\", \"executar_intencao_processo\")\n",
    "workflow.add_edge(\"executar_intencao_processo\", END)\n",
    "\n",
    "chatbot = workflow.compile()\n",
    "\n",
    "entrada_usuario = \"me fale sobre o resumo do processo 00002.003059/2024-15\"\n",
    "\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=entrada_usuario)],\n",
    "    \"intencao_usuario\": {\"intencao\": \"\", \"cod_processo\": \"\"},\n",
    "    \"is_valid\": False\n",
    "}\n",
    "\n",
    "resultado = chatbot.invoke(initial_state)\n",
    "\n",
    "for m in resultado[\"messages\"]:\n",
    "    print(f\"{m.type.upper()}: {m.content}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
